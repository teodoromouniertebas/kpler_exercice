---
title: "Kpler Technical Exercise"
author: "Teodoro Mounier Tebas"
format:
  html:
    code-fold: show
    code-tools: true
    toc: true
    toc-location: left
    toc-depth: 2
    theme: cosmo
    fontsize: 1em
    linestretch: 1.7
    grid:
      sidebar-width: 300px
      body-width: 1000px
      margin-width: 200px
      gutter-width: 1.5rem
execute:
  echo: true
  warning: false
  message: false
  error: false
  freeze: auto
editor: visual
---

<br>

## Instructions

#### **Objective**

Evaluate the candidate’s ability to build a lightweight internal tool for automating a common data wrangling task.

<br>

#### **Background & Context**

You’re supporting the **Refined Products team** at Kpler and are asked to streamline a **manual product classification task**. Analysts currently spend time standardizing product names from various sources into Kpler’s internal naming convention — your goal is to automate this.

<br>

#### **Provided Datasets**

-   **raw_product.csv**: A table of unstructured product labels from various providers.
-   **product_alias.csv**: A product alias mapping table used at Kpler.

<br>

#### **Your Task**

Build a User Interface through a web app that enables the following:

1.  **Data Normalization**

    -   Use `product_alias.csv` to map and normalize raw product names from `raw_product.csv`.
    -   Generate a cleaned version of the dataset with the mapped product names.

2.  **Interactive UI Features**

    The app should allow users to:

    -   Upload a raw product file (with a similar structure to `raw_product.csv`)
    -   Preview the cleaned data after alias mapping
    -   Download the normalized dataset as a CSV

3.  **Handling Unmapped Values**

    -   Detect and clearly display any product names from the raw dataset that do **not** match entries in the alias mapping table.

    -   Categorize these unmapped values into meaningful groups, such as:

        -   **Likely valid products** (potential matches worth reviewing)
        -   **Invalid entries** (e.g., misspellings, test strings, or irrelevant data to discard)

    -   Provide an interface for analysts to:

        -   Manually assign these to a Kpler product name
        -   Export the final matched output (including these manual corrections)

**Optional Challenge (Bonus)**

Enhance the tool by:

-   Implementing a **fuzzy matching** step for unmapped values
-   Letting the user **review and approve/reject fuzzy matches** before final export

<br>

<br>

## Exploratory Data Analysis

#### **Load necessary libraries**

```{r}
#| label: import libraries

library(tidyverse) # to manipulate the data
library(summarytools) # to summarize the data
library(kableExtra)  # to create nice tables
library(stringdist)  # to calculate the string distance
library(fuzzyjoin) # to join dataframes based on string distance 
```

<br>

#### **Import Data and First Check**

```{r}
#| label: import data

alias_product <- read_csv("data/raw_data/product_alias.csv")
raw_product <- read_csv("data/raw_data/raw_product.csv")
```

We can use `glimpse()` to get an overview of the structure (number of rows and columns and their types).

::: panel-tabset
##### alias_product

```{r}
#| label: glimpse alias_product

glimpse(alias_product)
```

##### raw_product

```{r}
#| label: glimpse raw_product

glimpse(raw_product)
```
:::

We can use `dfSummary()` to get a summary of the data, including the number of unique values, missing values, and the most frequent values.

::: panel-tabset
##### alias_product

```{r}
#| label: Summary of alias_product

print(dfSummary(alias_product, style = "grid", graph.magnif = 1, 
                valid.col = FALSE, varnumbers = FALSE, tmp.img.dir = "/tmp", 
                max.distinct.values = 5, headings = TRUE, method = "render", 
                col.widths  = c(300, 200, 100, 50, 20)),
      method = "render")
```

##### raw_product

```{r}
#| label: Summary of raw_product

print(dfSummary(raw_product, style = "grid", graph.magnif = 1, 
                valid.col = FALSE, varnumbers = FALSE, tmp.img.dir = "/tmp", 
                max.distinct.values = 5, headings = TRUE, method = "render", 
                col.widths  = c(300, 200, 100, 50, 20)),
      method = "render")
```
:::

<br>

#### **Clean the data before the mapping**

After the check we need to clean the data before we can use it for the mapping. We will perform the following steps:

1.  Remove the **`{r} sum(duplicated(raw_product))` duplicates** and **`{r} sum(is.na(raw_product$raw_product))` missing values** from the `raw_product` table.

2.  Convert all the **IDs columns** to character. (best practice to have IDs as character)

::: panel-tabset
##### alias_product

```{r}
#| label: convert to character

alias_product_c <- alias_product |> 
  mutate(
      alias_id = as.character(alias_id),
      provider_id = as.character(provider_id),
      product_id = as.character(product_id))

glimpse(alias_product_c)
```

##### raw_product

```{r}
#| label: remove duplicates

raw_product_c <- raw_product |> 
  filter(!is.na(raw_product)) |> 
  distinct() |> 
  mutate(provider_id = as.character(provider_id)) |> 
  arrange(raw_product)

glimpse(raw_product_c)
```
:::

<br>

<br>

## Mapping

To build an application that automates the data cleaning and manipulation process, we’ll start by handling the task for this specific case. That’s why we’ll begin with the first part: **data normalization**, followed by the third part: **handling unmapped data**, before moving on to developing the full **application**.

<br>

#### **Data Normalization**

First, we will **join** the `raw_product_c` dataframe with the `alias_product_c` dataframe. Then, we will **filter** the products into two separate dataframes, one containing the products that have been mapped, and another for those that haven't, for use in the third part of the task.

::: panel-tabset
##### Mapped products

```{r}
#| label: Left Join

alias_product_c <- alias_product_c |> 
  select(alias_id, alias, mapped_product, product_id) |> 
  distinct()

# left join the raw_product_c with the alias_product_c
mapped_products <- raw_product_c |> left_join(alias_product_c, 
                             by = c("raw_product" = "alias")) |> 
  filter(!is.na(mapped_product))

# table of the mapped products
kbl(mapped_products) |> 
  kable_styling(fixed_thead = T,
                bootstrap_options = c("hover")) |> 
  scroll_box(height = "500px")
```

##### Unmapped products

```{r}
#| label: unnmapped values after left join

# unmapped products
unmapped_products <- raw_product_c |> left_join(alias_product_c, 
                             by = c("raw_product" = "alias")) |> 
  filter(is.na(mapped_product))

# table of the mapped products
kbl(unmapped_products) |> 
  kable_styling(fixed_thead = T,
                bootstrap_options = c("hover")) |> 
  scroll_box(height = "500px")
```
:::

#### **Conclusion after mapping**

After the mapping, we have two dataframes:

-   `mapped_products` : dataframe with the **`{r} nrow(mapped_products)`** products that have been successfully mapped to Kpler's internal naming convention.

-   `unmapped_products` : dataframe with the rest of the products that could not be mapped representing **`{r} nrow(unmapped_products)`** products.

<br>

#### **Handling unmapped values**

We will use the `fuzzjoin` library to suggest matches between unmatched product names and aliases using string similarity. This will help us categorize unmapped products into two groups, **likely valid products** and **invalid entries**.

We will use the Jaro-Winkler distance method to find similar strings. The `stringdist_left_join()` function will be used to join the `unmapped_products` dataframe with the `alias_product_c` dataframe based on the similarity of the product names.

::: panel-tabset
##### Likely valid products

```{r}
#| label: categorize unmapped products in Likely valid products

likely_valid_products <- unmapped_products |>
  select(raw_product, provider_id) |>
  stringdist_left_join(
    alias_product_c, 
    by = c("raw_product" = "alias"), 
    method = "jw",
    max_dist = 0.2,
    distance_col = "distance") |> 
  arrange(raw_product, distance) |>
  group_by(raw_product, provider_id) |>
  slice(1) |> 
  ungroup() |>
  filter(!is.na(mapped_product))

# table of the likely valid products (i select only the relevant columns)
kbl(likely_valid_products |> select(raw_product, alias, mapped_product, distance)) |> 
  kable_styling(fixed_thead = T,
                bootstrap_options = c("hover")) |> 
  scroll_box(height = "500px")
```

##### Invalid entries

```{r}
#| label: Invalid entries

invalid_entries <- unmapped_products |>
  select(raw_product, provider_id) |>
  stringdist_left_join(
    alias_product_c, 
    by = c("raw_product" = "alias"), 
    method = "jw",
    max_dist = 0.2,
    distance_col = "distance") |> 
  arrange(raw_product, distance) |>
  group_by(raw_product, provider_id) |>
  slice(1) |>
  ungroup() |>
  filter(is.na(mapped_product))

# table of Invalid entries
kbl(invalid_entries |> select(raw_product, alias, mapped_product, distance)) |> 
  kable_styling(fixed_thead = T,
                bootstrap_options = c("hover")) |> 
  scroll_box(height = "500px")
```
:::

#### **Conclusion after handling unmapped values**

After categorizing the unmapped products, we have two dataframes:

-   `likely_valid_products` : dataframe with the **`{r} nrow(likely_valid_products)`** likely valid products that have been mapped with the fuzzy matching method.

-   `invalid_entries` : dataframe with the **`{r} nrow(invalid_entries)`** invalid entries that could not be mapped even with the fuzzy matching approach.

<br>

<br>

## Application

To build the application, i use the `shiny` and `bslib` library. Here is the link to the application published on *shinyapps.io*: [kpleRapp](https://teodoromouniertebas.shinyapps.io/kpleRapp/)

```{r}
#| label: Code shiny app
#| eval: false

library(shiny)
library(DT)
library(dplyr)
library(readr)
library(stringdist)
library(fuzzyjoin)
library(bslib)

# Load alias mapping file
alias_product <- read_csv("data/product_alias.csv")

# UI part
ui <- page_sidebar(
  theme = bs_theme(
    version = 5,
    bootswatch = "cerulean",
    primary = "#FF5349",
    font_scale = 1,
    "headings-color" = "#29333C"
  ),
  title = "Kpler Product Normalization Tool",
  
  sidebar =
    list(
    fileInput("raw_file", "Upload 'raw_product.csv' file", accept = ".csv"),
    uiOutput("file_warning"),
    tags$hr(),
    downloadButton("download_cleaned", "Download mapped products", class = "btn-light"),
    br(),
    downloadButton("download_likely_valid", "Download fuzzyjoin products", class = "btn-light"),
    br(),
    downloadButton("download_unmatched", "Download unmapped products", class = "btn-light")
  ),

  navs_tab_card(
    nav_panel("Mapped products", DTOutput("cleaned_table")),
    nav_panel("Fuzzy join products", DTOutput("likely_table")),
    nav_panel("Unmapped products", DTOutput("unmatched_table"))
  )
)


# server part
server <- function(input, output, session) {
  raw_data <- reactiveVal()
  cleaned_data <- reactiveVal()
  likely_valid_data <- reactiveVal()
  unmatched_data <- reactiveVal()
  file_error <- reactiveVal(NULL)

observeEvent(input$raw_file, {
  req(input$raw_file)

  withProgress(message = "Processing file...", value = 0, {
    tryCatch({
      incProgress(0.1, detail = "Reading CSV...")
      raw <- read_csv(input$raw_file$datapath)

      if (!all(c("raw_product") %in% colnames(raw))) {
        file_error("Invalid file format: required column 'raw_product' not found.")
        raw_data(NULL)
        cleaned_data(NULL)
        likely_valid_data(NULL)
        unmatched_data(NULL)
        return(NULL)
      }

      file_error(NULL)
      raw_data(raw)

      incProgress(0.2, detail = "Cleaning alias table...")
      alias_product_c <- alias_product |> 
        mutate(
          alias_id = as.character(alias_id),
          provider_id = as.character(provider_id),
          product_id = as.character(product_id)
        ) |> 
        select(alias_id, alias, mapped_product, product_id) |> 
        distinct()

      incProgress(0.3, detail = "Preparing raw products...")
      raw_product_c <- raw |> 
        filter(!is.na(raw_product)) |> 
        distinct() |> 
        mutate(provider_id = as.character(provider_id)) |> 
        arrange(raw_product)

      incProgress(0.5, detail = "Joining mapped products...")
      mapped_products <- raw_product_c |> 
        left_join(alias_product_c, by = c("raw_product" = "alias")) |> 
        filter(!is.na(mapped_product))

      incProgress(0.6, detail = "Finding unmapped products...")
      unmapped <- raw_product_c |> 
        left_join(alias_product_c, by = c("raw_product" = "alias")) |> 
        filter(is.na(mapped_product))

      incProgress(0.75, detail = "Running fuzzy match...")
      likely_valid_products <- unmapped |> 
        select(raw_product, provider_id) |> 
        stringdist_left_join(
          alias_product_c, 
          by = c("raw_product" = "alias"), 
          method = "jw",
          max_dist = 0.2,
          distance_col = "distance") |> 
        arrange(raw_product, distance) |> 
        group_by(raw_product, provider_id) |> 
        slice(1) |> 
        ungroup() |> 
        filter(!is.na(mapped_product)) |> 
        select(raw_product, alias, mapped_product, distance)

      incProgress(0.9, detail = "Filtering truly unmatched products...")
      unmapped_products <- unmapped |> 
        select(raw_product, provider_id) |> 
        stringdist_left_join(
          alias_product_c, 
          by = c("raw_product" = "alias"), 
          method = "jw",
          max_dist = 0.2,
          distance_col = "distance") |> 
        arrange(raw_product, distance) |> 
        group_by(raw_product, provider_id) |> 
        slice(1) |> 
        ungroup() |> 
        filter(is.na(mapped_product)) |> 
        select(raw_product, alias, mapped_product)

      incProgress(1, detail = "Finalizing...")
      cleaned_data(mapped_products)
      likely_valid_data(likely_valid_products)
      unmatched_data(unmapped_products)

    }, error = function(e) {
      file_error("Error reading CSV file. Please check the file format.")
      raw_data(NULL)
      cleaned_data(NULL)
      likely_valid_data(NULL)
      unmatched_data(NULL)
    })
  })
})
  

  output$file_warning <- renderUI({
    if (!is.null(file_error())) {
      div(style = "color: red;", strong(file_error()))
    }
  })

  output$cleaned_table <- renderDT({
    req(cleaned_data())
    datatable(cleaned_data(),
      class = 'cell-border stripe',
      selection = "none",
      filter = "top")
  })

  output$likely_table <- renderDT({
    req(likely_valid_data())
    datatable(likely_valid_data(),
      class = 'cell-border stripe',
      selection = "none",
      filter = "top",
      editable = list(target = "cell", disable = list(columns = c(3, 4, 5))), 
      rownames = FALSE)|>
      formatStyle('raw_product',  color = '#FF5349', fontWeight = 'bold')
  })
  
  observeEvent(input$likely_table_cell_edit, {
    info <- input$likely_table_cell_edit
    df <- likely_valid_data()
    row <- info$row
    col <- info$col + 1
    df[row, col] <- DT::coerceValue(info$value, df[row, col])
    likely_valid_data(df)
  })
    
  output$unmatched_table <- renderDT({
    req(unmatched_data())
    datatable(unmatched_data(),
      class = 'cell-border stripe',
      selection = "none",
      filter = "top",
      editable = list(target = "cell", disable = list(columns = c(3, 4))), 
      rownames = FALSE) |>
      formatStyle('raw_product',  color = '#FF5349', fontWeight = 'bold')
  })
  
  observeEvent(input$unmatched_table_cell_edit, {
    info <- input$unmatched_table_cell_edit
    df <- unmatched_data()
    row <- info$row
    col <- info$col + 1
    df[row, col] <- DT::coerceValue(info$value, df[row, col])
    unmatched_data(df)
  })
  


  output$download_cleaned <- downloadHandler(
    filename = function() { "cleaned_products.csv" },
    content = function(file) {
      write_csv(cleaned_data(), file)
    }
  )

    output$download_likely_valid <- downloadHandler(
    filename = function() { "download_likely_valid_products.csv" },
    content = function(file) {
      write_csv(likely_valid_data(), file)
    }
  )
    
  output$download_unmatched <- downloadHandler(
    filename = function() { "unmatched_products.csv" },
    content = function(file) {
      write_csv(unmatched_data(), file)
    }
  )
}


# Run the application
shinyApp(ui, server)

```
